1. Algorithms complexity (understanding, big O notation, complexity of common algorithms)
	In computer science, the time complexity is the computational complexity that describes the amount of time it takes to run an algorithm. 
	Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary 
	operation takes a fixed amount of time to perform. Thus, the amount of time taken and the number of elementary operations performed by the 
	algorithm are taken to differ by at most a constant factor.
	

2. Array sorting methods(bubble sort, quick sort, merge sort)
	Bubble Sort is the simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in wrong order.
	Worst and Average Case Time Complexity: O(n*n). Worst case occurs when array is reverse sorted. Best Case Time Complexity: O(n). Best case 
	occurs when array is already sorted.  
	Quicksort (sometimes called partition-exchange sort) is an efficient sorting algorithm. Quicksort is a divide-and-conquer algorithm. It works 
	by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than 
	or greater than the pivot. The sub-arrays are then sorted recursively. This can be done in-place, requiring small additional amounts of memory 
	to perform the sorting. Mathematical analysis of quicksort shows that, on average, the algorithm takes O(n log n) comparisons to sort n items. 
	In the worst case, it makes O(n^2) comparisons, though this behavior is rare. The steps for in-place Quicksort are: 1) Pick an element, called 
	a pivot, from the array. 2) Partitioning: reorder the array so that all elements with values less than the pivot come before the pivot, while 
	all elements with values greater than the pivot come after it (equal values can go either way). After this partitioning, the pivot is in its 
	final position. This is called the partition operation. 3) Recursively apply the above steps to the sub-array of elements with smaller values 
	and separately to the sub-array of elements with greater values.
	In computer science, merge sort (also commonly spelled mergesort) is an efficient, general-purpose, comparison-based sorting algorithm. Most 
	implementations produce a stable sort, which means that the order of equal elements is the same in the input and output. Merge sort is a divide 
	and conquer algorithm that was invented by John von Neumann in 1945. Conceptually, a merge sort works as follows: 1) Divide the unsorted list 
	into n sublists, each containing one element (a list of one element is considered sorted). 2) Repeatedly merge sublists to produce new sorted 
	sublists until there is only one sublist remaining. This will be the sorted list.
	

3. Tree structure(construction, traversal)
	In computer science, a tree is a widely used abstract data type (ADT) that simulates a hierarchical tree structure, with a root value and subtrees 
	of children with a parent node, represented as a set of linked nodes. A tree data structure can be defined recursively as a collection of nodes 
	(starting at a root node), where each node is a data structure consisting of a value, together with a list of references to nodes (the "children"), 
	with the constraints that no reference is duplicated, and none points to the root. Alternatively, a tree can be defined abstractly as a whole 
	(globally) as an ordered tree, with a value assigned to each node. Both these perspectives are useful: while a tree can be analyzed mathematically 
	as a whole, when actually represented as a data structure it is usually represented and worked with separately by node (rather than as a set of nodes 
	and an adjacency list of edges between nodes, as one may represent a digraph, for instance). For example, looking at a tree as a whole, one can talk 
	about "the parent node" of a given node, but in general as a data structure a given node only contains the list of its children, but does not contain 
	a reference to its parent (if any).
	

4. Binary search algorithm
	is a search algorithm that finds the position of a target value within a sorted array.[4][5] Binary search compares the target value to the middle 
	element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, 
	again taking the middle element to compare to the target value, and repeating this until the target value is found. If the search ends with the 
	remaining half being empty, the target is not in the array.


5. Hash table(creating, collisions)
	In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys 
	to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the 
	desired value can be found. Ideally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect 
	hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are 
	always accommodated in some way. In a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of 
	the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key-value pairs, at 
	(amortized) constant average cost per operation. In many situations, hash tables turn out to be on average more efficient than search trees 
	or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative 
	arrays, database indexing, caches, and sets.

6. Stack, queue, linked list(construction, understanding, usage)
	STACK is an abstract data type that serves as a collection of elements, with two principal operations: 1) push, which 
	adds an element to the collection, and 2) pop, which removes the most recently added element that was not yet removed. The order in which 
	elements come off a stack gives rise to its alternative name, LIFO (last in, first out). Additionally, a peek operation may give access to 
	the top without modifying the stack.
	QUEUE - a collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence 
	and removal from the other end of the sequence. By convention, the end of the sequence at which elements are added is called the back, tail, 
	or rear of the queue and the end at which elements are removed is called the head or front of the queue, analogously to the words used when 
	people line up to wait for goods or services. The operation of adding an element to the rear of the queue is known as enqueue, and the operation 
	of removing an element from the front is known as dequeue. Other operations may also be allowed, often including a peek or front operation that 
	returns the value of the next element to be dequeued without dequeuing it. The operations of a queue make it a first-in-first-out (FIFO) data 
	structure. In a FIFO data structure, the first element added to the queue will be the first one to be removed. This is equivalent to the 
	requirement that once a new element is added, all elements that were added before have to be removed before the new element can be removed. 
	A queue is an example of a linear data structure, or more abstractly a sequential collection. Queues are common in computer programs, where 
	they are implemented as data structures coupled with access routines, as an abstract data structure or in object-oriented languages as classes. 
	Common implementations are circular buffers and linked lists. Queues provide services in computer science, transport, and operations research 
	where various entities such as data, objects, persons, or events are stored and held to be processed later. In these contexts, the queue 
	performs the function of a buffer. Another usage of queues is in the implementation of breadth-first search.
	LINKED LIST is a linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element 
	points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence. In its most basic form, 
	each node contains: data, and a reference (in other words, a link) to the next node in the sequence. This structure allows for efficient 
	insertion or removal of elements from any position in the sequence during iteration. More complex variants add additional links, allowing 
	more efficient insertion or removal of nodes at arbitrary positions. A drawback of linked lists is that access time is linear (and difficult 
	to pipeline). Faster access, such as random access, is not feasible. Arrays have better cache locality compared to linked lists.
